---
phase: 10-real-data-integration
plan: 01
type: execute
depends_on: []
files_modified:
  - scripts/scrape-ethics.py
  - scripts/refresh-data.sh
  - package.json
  - CLAUDE.md
---

<objective>
Integrate SC Ethics Commission scraper into the election map data pipeline.

Purpose: Enable automated refresh of real candidate data from the SC Ethics Commission website, replacing manual data updates with an automated pipeline.

Output: Working data refresh pipeline that scrapes ethics filings, processes them through the existing data transformation scripts, and outputs updated candidates.json.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-performance-optimization/09-01-SUMMARY.md

# External reference (working scraper to adapt):
# /Users/russellteter/Desktop/sc-ethics-report-monitor/src/monitor.py

# Existing data pipeline:
@scripts/process-data.py
@src/data/party-data.json

**Prior decisions:**
- Phase 2: Real county officials data scraped from sheriffsc.org + sccounties.org
- State House/Senate candidate data comes from SC Ethics Commission Initial Reports
- Party enrichment uses manual party-data.json + incumbent matching

**Existing infrastructure:**
- Working Playwright scraper exists in separate project (sc-ethics-report-monitor)
- process-data.py expects ethics data in specific JSON format
- Party data maintained in src/data/party-data.json

**Data flow:**
1. Scrape SC Ethics Commission (Playwright) → state.json format
2. Transform to process-data.py input format
3. Run process-data.py with party enrichment
4. Output: src/data/candidates.json
5. Copy to public/data/ for deployment
</context>

<tasks>

<task type="auto">
  <name>Task 1: Adapt ethics scraper for election map project</name>
  <files>scripts/scrape-ethics.py</files>
  <action>
Create scripts/scrape-ethics.py by adapting the working scraper from /Users/russellteter/Desktop/sc-ethics-report-monitor/src/monitor.py.

Key adaptations:
1. Remove email notification code (not needed for data pipeline)
2. Remove SendGrid/Resend dependencies
3. Keep only the scraping functions: scrape_recent_reports(), scrape_2025_calendar_year(), is_house_or_senate(), parse_date()
4. Output to scripts/data/ethics-state.json (same format as original state.json)
5. Add CLI argument for output path
6. Add --year argument to specify election year (default: current year)

Keep the Playwright-based approach (the Ethics site is JavaScript-heavy SPA).

Output JSON structure (matching what process-data.py expects):
```json
{
  "reports_with_metadata": {
    "report_id": {
      "candidate_name": "Last, First",
      "office": "SC House of Representatives District N",
      "report_name": "Initial Report 2026",
      "filed_date": "2026-01-08",
      "url": "https://ethicsfiling.sc.gov/..."
    }
  },
  "historical_2025": {
    "reports": { ... same structure ... }
  }
}
```

Add requirements: playwright, requests (already in requirements.txt from other scrapers)
  </action>
  <verify>
```bash
# Install playwright browsers if needed
python -m playwright install chromium 2>/dev/null || true

# Run scraper with limited pages for verification
cd /Users/russellteter/Desktop/sc-election-map-2026
python scripts/scrape-ethics.py --max-pages 1 --output scripts/data/ethics-test.json

# Verify output format
python -c "import json; d=json.load(open('scripts/data/ethics-test.json')); print(f'Reports: {len(d.get(\"reports_with_metadata\", {}))}'); print('Structure OK' if 'reports_with_metadata' in d else 'MISSING KEY')"
```
  </verify>
  <done>
- scrape-ethics.py creates valid JSON output
- Output contains reports_with_metadata with expected fields
- Script runs without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Create unified data refresh script</name>
  <files>scripts/refresh-data.sh, package.json</files>
  <action>
Create scripts/refresh-data.sh that orchestrates the full data pipeline:

```bash
#!/bin/bash
# Data refresh pipeline for SC Election Map
# Usage: ./scripts/refresh-data.sh [--full]

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

echo "=== SC Election Map Data Refresh ==="
echo "Started: $(date)"

# Step 1: Scrape SC Ethics Commission
echo ""
echo "[1/4] Scraping SC Ethics Commission..."
python "$SCRIPT_DIR/scrape-ethics.py" \
  --output "$SCRIPT_DIR/data/ethics-state.json" \
  --max-pages 5

# Step 2: Process ethics data with party enrichment
echo ""
echo "[2/4] Processing candidate data..."
python "$SCRIPT_DIR/process-data.py" "$SCRIPT_DIR/data/ethics-state.json"

# Step 3: Copy to public/data for deployment
echo ""
echo "[3/4] Copying to public/data/..."
cp "$PROJECT_ROOT/src/data/candidates.json" "$PROJECT_ROOT/public/data/candidates.json"

# Step 4: Verify
echo ""
echo "[4/4] Verification..."
CANDIDATE_COUNT=$(python -c "import json; d=json.load(open('$PROJECT_ROOT/public/data/candidates.json')); print(sum(len(v['candidates']) for v in d['house'].values()) + sum(len(v['candidates']) for v in d['senate'].values()))")
echo "Total candidates: $CANDIDATE_COUNT"

echo ""
echo "=== Data Refresh Complete ==="
echo "Output: public/data/candidates.json"
echo "Finished: $(date)"
```

Make executable: chmod +x scripts/refresh-data.sh

Add npm script to package.json:
```json
"scripts": {
  "refresh-data": "bash scripts/refresh-data.sh"
}
```
  </action>
  <verify>
```bash
cd /Users/russellteter/Desktop/sc-election-map-2026

# Verify script exists and is executable
ls -la scripts/refresh-data.sh

# Verify npm script added
grep "refresh-data" package.json

# Run a dry test of the pipeline (scraper already tested in Task 1)
echo "Pipeline script created successfully"
```
  </verify>
  <done>
- refresh-data.sh exists and is executable
- npm run refresh-data command available
- Script orchestrates scrape → process → copy flow
  </done>
</task>

<task type="auto">
  <name>Task 3: Update documentation and ensure data directory</name>
  <files>CLAUDE.md, scripts/data/.gitkeep</files>
  <action>
1. Create scripts/data/ directory for intermediate files:
   - mkdir -p scripts/data
   - touch scripts/data/.gitkeep
   - Add scripts/data/*.json to .gitignore (intermediate files, not committed)

2. Update CLAUDE.md Commands section to document the data refresh:

Add under "## Commands":
```markdown
# Data Pipeline
npm run refresh-data   # Scrape Ethics Commission + regenerate candidates.json
```

Add new section after "## Data Flow":
```markdown
## Data Refresh Pipeline

To update candidate data from the SC Ethics Commission:

```bash
npm run refresh-data
```

This runs the full pipeline:
1. **Scrape** - Playwright scrapes ethicsfiling.sc.gov for Initial Reports
2. **Process** - Merges with party-data.json for party enrichment
3. **Output** - Generates public/data/candidates.json

**Prerequisites:**
- Python 3.11+
- Playwright: `pip install playwright && python -m playwright install chromium`

**Manual scraping (advanced):**
```bash
python scripts/scrape-ethics.py --max-pages 10 --output scripts/data/ethics-state.json
python scripts/process-data.py scripts/data/ethics-state.json
cp src/data/candidates.json public/data/candidates.json
```
```
  </action>
  <verify>
```bash
cd /Users/russellteter/Desktop/sc-election-map-2026

# Verify directory created
ls -la scripts/data/

# Verify .gitignore updated
grep "scripts/data" .gitignore || echo "Need to add to .gitignore"

# Verify CLAUDE.md updated
grep "refresh-data" CLAUDE.md
```
  </verify>
  <done>
- scripts/data/ directory exists with .gitkeep
- Intermediate JSON files excluded from git
- CLAUDE.md documents the data refresh pipeline
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python scripts/scrape-ethics.py --help` shows usage
- [ ] `npm run refresh-data` command exists in package.json
- [ ] scripts/refresh-data.sh is executable
- [ ] CLAUDE.md documents the data refresh process
- [ ] No new TypeScript/lint errors introduced
</verification>

<success_criteria>
- Ethics scraper adapted and working in election map project
- Unified refresh script orchestrates full pipeline
- npm run refresh-data available as single command
- Documentation updated for data refresh workflow
- Intermediate files properly gitignored
</success_criteria>

<output>
After completion, create `.planning/phases/10-real-data-integration/10-01-SUMMARY.md`:

# Phase 10 Plan 01: Ethics Scraper Integration Summary

**[Substantive one-liner about what was accomplished]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `scripts/scrape-ethics.py` - SC Ethics Commission Playwright scraper
- `scripts/refresh-data.sh` - Unified data refresh pipeline
- `package.json` - Added refresh-data npm script
- `CLAUDE.md` - Documented data refresh process

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 10 complete - v1.1 SC Voter Guide Enhancement milestone ready for completion.
</output>
