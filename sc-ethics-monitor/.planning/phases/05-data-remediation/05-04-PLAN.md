---
phase: 05-data-remediation
plan: 04
type: standard
---

# Plan 05-04: Run Candidate Discovery Pipeline

<objective>
Execute the candidate discovery pipeline that was built in Phase 4 but never run in production.

Purpose: The pipeline (213+ tests passing) can discover candidates from Ballotpedia, SCDP, and SCGOP websites. It needs to be run to populate the system with candidates who have declared but not yet filed with Ethics Commission.

Output: Discovery pipeline executed, new candidates added to Google Sheet, coverage report generated.
</objective>

<context>
@.planning/phases/05-data-remediation/DESIGN.md
@.planning/phases/04-candidate-discovery/DESIGN.md
@src/candidate_discovery/__init__.py
@src/candidate_discovery/aggregator.py
@scripts/verify_discovery.py
@src/config.py
</context>

<tasks>

<task type="auto" id="1">
  <name>Verify discovery configuration</name>
  <action>
    Check `src/config.py` for discovery settings:
    - DISCOVERY_ENABLED should be true
    - DISCOVERY_SOURCES should include ballotpedia, scdp, scgop
    - FIRECRAWL_API_KEY should be set (env var)
    - NAME_SIMILARITY_THRESHOLD should be 0.85

    Document any missing configuration.
  </action>
  <verify>Configuration verified and documented</verify>
  <done>Discovery configuration is correct</done>
</task>

<task type="auto" id="2">
  <name>Verify Firecrawl API access</name>
  <action>
    Test Firecrawl API connectivity:
    ```bash
    python -c "from firecrawl import FirecrawlApp; f = FirecrawlApp(); print(f.scrape('https://ballotpedia.org'))"
    ```

    Verify API key is valid and has sufficient credits.
  </action>
  <verify>Firecrawl test request succeeds</verify>
  <done>Firecrawl API access confirmed</done>
</task>

<task type="auto" id="3">
  <name>Run discovery verification script</name>
  <action>
    Execute the verification script in dry-run mode:
    ```bash
    cd /Users/russellteter/Desktop/sc-election-map-2026/sc-ethics-monitor
    python scripts/verify_discovery.py --dry-run --verbose
    ```

    Review output for any configuration issues.
  </action>
  <verify>Dry-run completes without errors</verify>
  <done>Discovery pipeline ready for production run</done>
</task>

<task type="auto" id="4">
  <name>Execute discovery pipeline - Ballotpedia</name>
  <action>
    Run discovery with Ballotpedia source:
    ```bash
    cd /Users/russellteter/Desktop/sc-election-map-2026/sc-ethics-monitor
    DISCOVERY_SOURCES=ballotpedia python scripts/verify_discovery.py --verbose
    ```

    Monitor for rate limiting and errors.
    Log count of candidates discovered.
  </action>
  <verify>Ballotpedia discovery completes, candidates logged</verify>
  <done>Ballotpedia candidates discovered and logged</done>
</task>

<task type="auto" id="5">
  <name>Execute discovery pipeline - Party sources</name>
  <action>
    Run discovery with SCDP and SCGOP sources:
    ```bash
    cd /Users/russellteter/Desktop/sc-election-map-2026/sc-ethics-monitor
    DISCOVERY_SOURCES=scdp,scgop python scripts/verify_discovery.py --verbose
    ```

    Log count of candidates discovered per source.
  </action>
  <verify>Party source discovery completes, candidates logged</verify>
  <done>SCDP and SCGOP candidates discovered</done>
</task>

<task type="auto" id="6">
  <name>Review discovered candidates</name>
  <action>
    Examine the discovery results:
    1. Total candidates discovered
    2. Breakdown by source
    3. Breakdown by party
    4. Duplicates detected and merged
    5. Conflicts requiring review

    Document any anomalies or concerns.
  </action>
  <verify>Discovery results reviewed and documented</verify>
  <done>Discovery results analyzed</done>
</task>

<task type="auto" id="7">
  <name>Sync discovered candidates to Google Sheets</name>
  <action>
    Execute sheets integration:
    ```bash
    cd /Users/russellteter/Desktop/sc-election-map-2026/sc-ethics-monitor
    python -c "from src.candidate_discovery.sheets_integration import DiscoverySheetIntegration; ..."
    ```

    Or use monitor.py with FORCE_DISCOVERY=1:
    ```bash
    FORCE_DISCOVERY=1 python src/monitor.py --force-discovery
    ```
  </action>
  <verify>Candidates synced to Google Sheet</verify>
  <done>Discovered candidates appear in Candidates tab</done>
</task>

<task type="auto" id="8">
  <name>Generate coverage report</name>
  <action>
    Use the reporter module to generate coverage metrics:
    - Districts with candidates vs without
    - Coverage percentage
    - Sources contributing data
    - Candidates needing party verification

    Save report for documentation.
  </action>
  <verify>Coverage report generated</verify>
  <done>Coverage metrics documented</done>
</task>

</tasks>

<verification>
- [ ] Discovery configuration verified
- [ ] Firecrawl API access confirmed
- [ ] Dry-run completes successfully
- [ ] Ballotpedia discovery executed
- [ ] SCDP/SCGOP discovery executed
- [ ] Results reviewed for accuracy
- [ ] Candidates synced to Google Sheet
- [ ] Coverage report generated
</verification>

<success_criteria>
- Discovery pipeline runs without errors
- Candidates discovered from all configured sources
- New candidates appear in Google Sheet Candidates tab
- Coverage report shows improvement over baseline
- No data loss or corruption during sync
</success_criteria>

<output>
Create 05-04-SUMMARY.md documenting:
- Discovery execution results:
  - Ballotpedia: N candidates from M districts
  - SCDP: N candidates
  - SCGOP: N candidates
- Deduplication stats (raw vs merged)
- Conflicts found and resolution
- Coverage metrics:
  - Districts with candidates: X/170
  - Coverage percentage
- Candidates needing party detection
- Recommended follow-up actions
</output>
